# Tables {#tables}

This chapter covers navigating tabular data with R.

The first two sections -- on magrittr and data.table -- cover packages that help me work more efficiently, to the point where I regard them as essential. They'll be used throughout the rest of this document. They don't have any dependencies on other packages, and I expect they'll be available as long as R is. It will be assumed in subsequent sections that these libraries have been loaded:

```{r loadem, echo=FALSE, warning=FALSE}
library(magrittr)
library(data.table)
```

## Magrittr

[Magrittr](https://cran.r-project.org/package=magrittr) introduces syntax with "pipes," improving readability by unnesting function calls:

```{r magrittr-calls, eval=FALSE}
# we can do
x %>% f %>% g %>% h
# instead of 
h(g(f(x)))
```

In addition, it allows more compact function definitions (\@ref(function-writing)):

```{r magrittr-funs}
fun = . %>% .^2 %>% sum %>% sqrt
fun(1:3)
```

Despite these advantages, magrittr can slow down code, so avoid using it anywhere where speed might be an issue.

To install, just use CRAN:

```{r inst-mgr, eval=FALSE}
install.packages('magrittr')
```

The name is a pun on [RenÃ© Magritte's pipe painting](https://en.wikipedia.org/wiki/The_Treachery_of_Images).

## data.table {#data-table}

[Data.table](http://r-datatable.com) offers a variant of the data frame class (from \@ref(data-frames)), optimized for fast sorted and grouped operations and enhanced with cleaner syntax. It also bundles in a variety of other improvements on base R functionality.

### Modification by reference

In contrast with the rest of R, data.tables are primarily modified "in-place" without assigning the result, which can be much more efficient. As a first example, we can switch the class of a data frame to data.table:

```{r setDT}
DF = data.frame(
  x = letters[c(1, 2, 3, 4, 5)], 
  y = c(1, 2, 3, 4, 5), 
  z = c(1, 2, 3, 4, 5) > 3
)
str(DF)
setDT(DF)
str(DF)
```

We did not use `=` or `<-` to assign the result of `setDT`; the function simply altered `DF` in-place. All of data.table's functions named like `set*` do this.

### Factor vs character columns {#dt-factorvchar}

Another difference is that `data.frame` takes string input as a `factor` categorical variable (\@ref(factors)), as seen above; while `data.table` interprets it as character:

```{r DT}
DT = data.table(
  x = letters[c(1, 2, 3, 4, 5)], 
  y = c(1, 2, 3, 4, 5), 
  z = c(1, 2, 3, 4, 5) > 3
)
str(DT)
```

### Syntax

The third major difference is a change in syntax from a data frame's `DF[i,j]`, with `i` and `j` as indices, to SQL-style syntax that is cleaner for by-group operations:

    # this is only pseudocode:
    DT[where, select|update|do, by] # SQL verbs
    DT[i, j, by]                    # R function arguments

This should be read as:

1. Subset using `i`
1. Group using `by`
1. Do `j`

We can type column names as barewords here, and even form expressions in terms of columns:

```{r DT-ex}
DT[x > "b", sum(y), by=z]
```

```{block2 dt-optimized, type='rmd-details'}
**Optimized data.table calls.** The last call is optimized in a couple ways. First, the inequality in `i` triggers creation of an "index" in terms of `x`, making subsequent indexing on `x` faster thanks to binary search, documented at `?indices`. Second, the `sum` in `j` is computed using an optimized "grouped sum" or `gsum` computation, documented at `?GForce`.
```

```{block2 dt-verbose, type='rmd-details'}
**Verbose data.table messages.** To understand better how data.table works, I would recommend trying out the setting `options(datatable.verbose = TRUE)`. This option is similar to verbose output from an optimization call (reporting the value of the objective at each iteration, etc.). To only see verbose output for a single call, add `verbose = TRUE`. For example, to see see what I meant in the last paragraph, try `DT[x > "b", sum(y), by=z, verbose=TRUE]`.
```

The task for `j` can really be anything. For example, it's really handy for saving per-group plots:

```{r}
# note: this code will save to your current working directory
# type getwd() and read ?setwd for details

bwDT = data.table(MASS::birthwt)

pdf(file="birthweight_graphs.pdf")
bwDT[, {
  case = sprintf("ftv = %s, smoke = %s", .BY$high_vis, .BY$smoke)
  
  cat("Handling", case, "...\n")
  plot(
    age ~ lwt, 
    main = case
  )  
}, by=.(high_vis = ftv >= 1, smoke)]
dev.off()
```

For each group, we're now printing a line with `cat` and saving a plot. This is better than a `for` loop (\@ref(for-loops)), since we don't have to manually construct some "split-up data" to iterate over; don't have to worry about intermediate variables like `case` contaminating the global environment; and don't have do define what we're doing as a function of prespecified variables -- we can just use any columns of the data.table.

Plotting graphs is beyond the scope of this document, but the example above should make sense after reading the docs for each object, `?MASS::birtwt`, `?pdf`, et al.


caution re `by=` columns: use integers, characters, factors -- not floats

### Other features

Besides the data.table class, the package provides other useful features that will come up later:

- ITime and IDate date and time classes
- `fread` and `fwrite` for fast reading and writing of delimited files
- `dcast` and `melt` for reshaping tables

Because these disparate features are bundled together in data.table, we don't have to load more packages and worry about their complicated dependencies or namespace conflicts (\ref(namespaces)).

### Installation

Again, CRAN can be used:

```{r inst-dt, eval=FALSE}
install.packages('data.table')
```

However, the package is under active development, with new features available only in the development version. To install it, follow [the instructions from the package wiki](https://github.com/Rdatatable/data.table/wiki/Installation):

```{r inst-dt-dev, eval=FALSE}
remove.packages("data.table")
install.packages("data.table", type = "source",
  repos = "http://Rdatatable.github.io/data.table")
```

If using Windows, you'll need to first install [Rtools](https://cran.r-project.org/bin/windows/Rtools/) (requiring administrator privileges), as explained in the last link.

### Getting started

[The official vignettes](https://github.com/Rdatatable/data.table/wiki/Getting-started) for the package are a great way to start with the package. I started by reading some slides and the FAQ in full before using the package. 

## Input and output {#input-output}

### File paths

Don't give R paths like `"C:\data\input.csv"`. The backslash is an "escape character" and can't be used to delineate folders. There are a few alternatives:

- Escape the escape character: `"C:\\data\\input.csv"`
- Use forward slashes: `"C:/data/input.csv"`
- Build with `file.path`: `file.path("c:", "data", "input.csv")`

As far as I know, the latter two options will also work in Linux and so are preferable.

`dir()` and `list.files()` will list the contents of a folder. `getwd()` returns the current path (or "working directory"), while `setwd(new_path)` will change it.

`dir.create`, `file.copy` do what you would expect. See `?files` and `?files2` for related functions.

absolute vs relative paths, `normalizePath`

### `fread` to read delimited files {#fread}

zzz

### `.SDcols` for a set of columns

shortcuts: .SDcols = V1:V10, .SDcols = grep("^date_", names(DT)), etc

### Character columns

state.abb, state.names

tstrsplit

substring

### Factor columns

use characters most of the time, don't worry about memory. the real memory problems come from how data is organized, as discussed in \@ref(structuring-data).

show how ordered factors can be used to set up inequalities for strings

### Date and time columns {#dates-times}

as.IDate, IDateTime

wday, weekdays, etc.

show that max, min, inequalities work for dates and times

lapply + .SDcols with date conversion

### List columns

list columns -- somewhat clumsy, but sometimes convenient (no by=, shift(); inefficient %in% and match()). can store regression results, for example

consider unique %>% sort %>% toString/paste instead if it's just for browsing; or going to long format (see data structure)

### Source-file index columns

rbindlist idcol


### `fwrite` to write delimited files {#fwrite}

zzz

### Saving and loading R objects

with Rdata, use load() or just drag it into the window

### Reading and writing other formats

For "foreign" table formats (excel, stata, etc), use google. these I/O functions will always be in active development because the formats themselves are in flux. of course, it's unsafe to use such formats for long-term data storage

details: feather is eventually for storage and transfer but is still under heavy development at this point.

### Formatting the display of columns

remember: do rounding as late as possible -- don't start during the cleaning and exploration phase

## Exploring data {#exploring-data}

range, summary

Henk Harmsen on "ergonomics" https://rpubs.com/carbonmetrics/datatable_ihub

`e_bad = DT[, var, by=e_id][var==TRUE, e_id]; DT[.(e_id)] (simpler with having)`

`DT[, .N, by=e_id][order(-N)]`

creating temp vars, printing with []

DT[, do_stuff, j] %>% print(nrow=Inf) with magrittr (warning about performance hit in real nonexploratory code)

hist, hexbin

cor, cormat

x11() for multiple windows

eyeball-exploring models: curve

qqplot etc for the statistically literate, and other tools for ML people

### Browsing loaded objects {#browse-env}

ls()

rm()

tables()


### Subsetting {#dt-subset}

#### Selecting by value

This is analogous to a SQL WHERE clause or a Stata `if` clause.

```{r dt-sub-pre}
# example data
DT = data.table(Titanic)
```

```{r dt-sub}
DT[ Class == "Crew" & N > 100 ]
```

This syntax, `DT[i]`, is the subsetting task needed in the vast majority of cases. The rest of \@ref(dt-subset) can safely be skipped the first time through; it is mostly useful for reference.

#### Selecting by group statistic

This is analogous to a SQL HAVING clause.

```{r dt-sub-gstat}
DT[ , if (sum(N) < 300) .SD, by=Class ]
```

We are including the group only if it meets our condition. The structure `if (cond) x` returns `x` if the condition is true and nothing (`NULL`) otherwise, omitting those rows. `.SD` refers to the Subset of the Data associated with each `by=` group.

This syntax isn't as clean as a HAVING clause, but it is likely to improve.

#### Selecting rows within each group

```{r dt-sub-grow}
# select first row
DT[ , .SD[1L], by=Class ]
# select row(s) with highest count
DT[ , .SD[N == max(N)], by=Class ]
```

```{block2, type='rmd-details'}
**Efficient selection of rows within each group.**  The second task here is [somewhat inefficient](https://github.com/Rdatatable/data.table/issues/735) currently, with a faster workaround [provided by eddi](http://stackoverflow.com/a/16574176): `DT[DT[ , .I[N == max(N)], by=Class ]$V1]`. And [Arun provided a further improvement](http://stackoverflow.com/a/31854111), taking advantage of `gmax`, an efficient by-group `max` (see `?GForce`): `DT[DT[, max(N), by=Class], on=.(Class, N = V1)]`. The variable `.I` represents the row number in the full table, or at least it *should* do that. Currently, `.I` does [not always behave like this](https://github.com/Rdatatable/data.table/issues/1494). "V1" is the default name given to the result in `j`. 
```

#### Finding where a condition holds

To find where a condition holds:

```{r which}
cond = c("aleph", "baz", "boz") > "b"
which(cond)
```

So, it takes us from a logical index to one of positions. This can sometimes speed up computations; and is necessary when facing functions that don't take logical indices.

When using `which` on a matrix or array (see \@ref(matrix-array)), we can find out "where" in terms of row and column using the `arr.ind` option.

Beware of using `which` output as an index:

```{r bad-which}
x  = 1:5
w  = which(x^2 > 50)
x[-w]
```

We wanted to filter to where `x` meeting our condition, but instead we lost the whole vector. Straight-up logical filtering is the safer route here.

Data.table has `DT[i, which = TRUE]` syntax as well.


### Sorting

order(x, -y)

setorder

setkey

### Summaries {#dt-summary-stats}

#### The `summary` function

similar to stata

doesn't really return a useful object, only for printing

#### Collapsing a table

collapse

various custom summary functions

maybe mention GForce again


#### Counting missing values

mdesc, count missing per column colSums(is.na(.SD))


#### Tabulating {#counting-rows}

Tabulating or tallying

bwDT[, .N, by=ftv]

refer to table() and plot.table()

With a continuous variable `x`, it often doesn't make sense to tally values as in the last section. However, we can specify bins and find where the values fall:

```{r cut}
set.seed(1)
n  = 1000
x  = rchisq(n, df = 10)
xc = cut(x, breaks = c(0, 5, 10, 15, 20, Inf)) # or max(x) in place of Inf
table(xc)
```

See the note in `?cut` for details on more efficient alternatives:

> Instead of `table(cut(x, br))`, `hist(x, br, plot = FALSE)` is more efficient and less memory hungry. Instead of `cut(*, labels = FALSE)`, `findInterval()` is more efficient.



### Reshaping to wide

wide format is rarely useful for storing data (see structuring data)

but it is good for browsing

dcast

analogy with blacksmithing or something (re cast and melt), molten into its most flexible form, cast into a rigid shape for a particular purpose



## Modifying data in-place {#dt-subassign}

Creating, editing and removing columns are all done using `:=` in `j` of `DT[i, j, by]`. This functionality operates in-place, in the sense that the underlying data stays in the same place, which is more efficient in terms of how much RAM and time is taken.

```{block2, type='rmd-details'}
**What can be modified in-place?** The scope of in-place operations is currently limited to altering columns. Adding and removing rows by reference is not yet supported, since this is harder to do in R, thanks to its column-oriented storage of tables (contrasting with many database systems that store data rowwise for easy INSERT and DELETE queries).
```

### Creating columns {#dt-col-create}

```{r dt-add}
DT = data.table(
  x = letters[c(1, 2, 3, 4, 5)], 
  y = c(1, 2, 3, 4, 5), 
  z = c(1, 2, 3, 4, 5) > 3
)
# creating a column
DT[, u := 5:1][]
# creating multiple
DT[, `:=`(v = 2, w = 3L)][]
# creating with dynamic names
nms = c("a", "b", "c")
DT[, (nms) := .(1, 2, 3)][]
```

All of these tasks are performed in-place -- altering `DT` without making a new object. Usually, the results are not displayed. They appear here because `[]` is "chained" onto the end of each task.

```{block2, type='rmd-caution'}
**`:=` is the function both for creation and modification of columns.** This will be covered it more detail in subsequent sections, but is worth emphasising. In particular, this contrasts with Stata (which uses `gen`, `egen` and `replace`).
```

```{block2, type='rmd-details'}
**Iterative column creation.** The `` `:=`(...)`` syntax does *not* support iterative definitions like ``DT[, `:=`(W1 = u + y, W2 = W1^2)]``. One typical way of getting around this is ``DT[, `:=`(W1 = W1 <- u + y, W2 = W1^2)]``. The workings of this are not obvious to new R users, but the gist is: `W1 <- u + y` creates `W1` as an object in `DT[...]` and then returns its value, let's call it `v`. Now, `W2 = W1^2` can find `W1`, since it was created by `<-`; and `W1 = W1 <- u + y` simplifies to `W1 <- v`, where `v` is the return value of `W1 <- u + y`.
```

### Removing columns

```{r dt-remove}
nms = c("u", "v", "w", "a", "b", "c")
DT[, (nms) := NULL][]
```

A warning will print if you remove any columns that don't currently exist.

### Replacing entire columns

Data.table is careful about column types:

```{r dt-reptot, warning=TRUE}
DT[, a := 10L ][]  # Create a new column of integers
DT[, a := 21L ][]  # Replace it with another column of integers
DT[, a := 32.5 ][] # Replace it with a float
```

The verbose warning printed above is typical for the package and an excellent feature. Running the final command, data.table knows that `a` is of integer type and sees that 32.5 is conspiciously *not an integer*. So it gives a warning when coercing 32.5 to an integer (to match `a`). Elsewhere in R, `a` would be coerced to match the float `32.5` -- probably not the behavior we want -- with no warning. That is, if we have `x <- c(21L, 22L)`, we can freely assign `x[1] <- 32.5`; and the same freedom (by which I mean "danger") is present even if `x` is a data frame column.

As indicated in the warning message, if we want to change `a`'s type, we have to explicitly replace all values:

```{r dt-reptot-class, warning=TRUE}
DT[, a := rep(32.5, .N) ][]
```

The coercion is done silently, but it can be made more visible by turning on `verbose`.

### Replacing columns conditionally {#dt-ifelse}

This is analogous to a SQL UPDATE query or a replace statement in Stata. To illustrate, we will look again at a vectorized `if`/`else` assignment, mentioned in \@ref(ifelse):

```{r dt-ifelse-1, results="hide"}
DT[     , b := "Ants"] # initialize to baseline value
```
```{r dt-ifelse-2}
DT[y > 1, b := "Bats"][] # replace based on a condition
```

This can also be done with chaining:

```{r dt-ifelse-chain}
DT[, b := "Ants"][y > 1, b := "Bats"]
```

This chaining works because `DT[...][...]` is evaluated like `(DT[...])[...]` and the return value of the piece in parentheses is a data.table.

As we saw in the last section, partial replacement of a column will trigger a warning if the classes don't match:

```{r dt-ifelse-conflict, warning=TRUE}
DT[, b := "Ants"][y > 1, b := 111]
```

Another nice feature, similar to Stata, is reporting of the number of rows modified. This can be seen by turning `verbose` on:

```{r dt-ifelse-count}
DT[, b := "Ants"][y > 1, b := "Gerbils", verbose = TRUE]
```


### Iterating over columns

Suppose we want to find the maximum value in each column. As we saw in \@ref(lapply-df), we can do this like `lapply(DT, max)`. The `lapply` function is an option here because a data.table, like a data frame, is a list of columns.

With data.table, however, we can go beyond a simple `lapply`. We can, for example, compute the max within each value of `z`, limiting computation to numeric columns:

```{r lapply-dt}
DT[, 
   lapply(.SD, max)
, by=z, .SDcols = { sapply(DT, is.numeric) }]
```

`.SDcols` is used to filter the columns that appear in `.SD`, the subset of data available in `j`. 

```{block2 dt-set, type='rmd-details'}
**Another interface, `set`.** The `set` function can also be used to modify data by reference. It has efficiency benefits in some cases, but it essentially a more limited version of `:=`.
```

... split this section into iterating over columns and iterating over groups. explain that by= will take any appropriate-length vector, warn about by=1:nrow(DT)

### Avoiding in-place modification

If you want to create a new data.table instead of modifying in-place, use

```{r dt-copy, eval=FALSE}
DT2 = copy(DT1)
```

We have to use this instead of `DT2 = DT1` since with the latter we have only created a new "pointer" to the first data set. I routinely make copies after reading in data (\@ref(fread)) so that I can back out where I tripped over something in the process of data cleaning.

## Joins {#dt-merging}

You can call them "joins" or "merges."

```{r dt-join-prea, echo=c(1:2,4L)}
# example data
a = data.table(id = c(1L, 1L, 2L, 3L, NA_integer_), x = 11:15)
a
b = data.table(id = 1:2, y = -(1:2))
b
```

The idiom for a simple join is `x[i]` or `x[i, on=.(...)]`: 

```{r dt-join}
a[b, on=.(id)]
```

Think of `x[i]` as using index `i` to look up rows of `x`, in the same way an "index matrix" can look up elements of a matrix (\@ref(matrix-extract)). 

### Handling multiply-matched rows {#join-multimatch}

In this example, we are indexing by rows of `b` and so get matches for every row of `b`. By default, we get *all* matches in `a`, but this can be tweaked:

```{r dt-join-mult}
a[b, on=.(id), mult="first"]
```

Now each row of `b` only returns the first matching row (from the top) in `a`.

### Handling unmatched rows

Flipping it around, if we use `a` to index `b`, we have some index rows from `a` that don't have any matches in `b`:

```{r dt-join-nomatch}
b[a, on=.(id)]
```

These unmatched rows still show up in the result, which is usually nice. However, this behavior can also be tweaked:

```{r dt-join-nomatch0}
b[a, on=.(id), nomatch=0]
```

```{block2 dt-dot, type='rmd-caution'}
**The `.()` convenience function.** Inside certain arguments of `DT[...]`, like `on=` above, we can use the shorthand `.()`, which stands for `list()`.
```

```{block2 dt-merge-res, type='rmd-details'}
**Diagnostics for merges.** In Stata, joins report on how well they went -- did everything match? how many didn't match? The analogous question for an `x[i]` join is -- for each row of `i`, how many matches did we find in `x`? To see the answer, use `b[a, on=.(id), .N, by=.EACHI]`.
```

We also have the option of selecting *unmatched* rows:

```{r dt-join-notjoin}
a[!b, on=.(id)]
```

This "not-join" or "anti-join" returns all rows of `a` that are not matched by rows in `b`.

### Fancy joins

Besides not-joins, there are many join features introduced elsewhere in this tutorial: aggregate joins (by=.EACHI), cross joins, update joins, rolling joins, non-equi joins.

If a table is always joined on the same column(s), these can be set as its "key." Setting the key of `x` sorts the table and allows for skipping `on=` during `x[i,on=]` joins. See `?setkey`. 


## Organizing relational tables {#structuring-data}

background: tidy data / database design

### Reshaping to long format


### Choosing tables and keys


### Listing levels

make a "skeleton" for the data

consider igraph if the order does not matter

use CJ(col1, col2), maybe seq

if it's not cartesian, then DT[, col2, by=col1]


### Exploring levels

setdiff, union, intersect (works with data.table from 1.9.8+)

does the table have any dupes?

does the table have all levels?

stopifnot

### Collapsing {#aggregate-join}

essentially an aggregate join -- we join so that we can aggregate

maybe collapsing because we want a table aggregated at a higher level

maybe collapsing because we have "duplicates" hanging around for other reasons

unique, duplicated + fromLast

```{block2 dt-join-beware, type='rmd-caution'}
**Beware `DT[i,on=,j,by=bycols]`.** Only `by=.EACHI` works in a join. Typing other `by=` values there will cause `i`'s columns to become unavailable. This [may eventually change](https://github.com/Rdatatable/data.table/issues/733).
```

use CJ for missing levels

### Expanding

CJ + unique


use CJ for missing levels

Suppose we have a table measuring wealth by person and year.

```{r expandrows-pre, echo=1}
DT = data.table(psn_id = c(1L, 1L, 2L), year = c(1998L, 2000L, 2000L), wealth = 24:22)
DT
```

Now we want a person-year row for every every person and for every year from the lowest to the highest. We can do this with `CJ` and a standard join:

```{r expandrows, echo=1}
DT = data.table(psn_id = c(1L, 1L, 2L), year = c(1998L, 2000L, 2000L), wealth = 24:22)
DT
```


### Update joins

we join so that we can update the table on the left

As we saw in \@ref(dt-ifelse), we can do a SQL-style UPDATE like `x[i, var := ...]`:

```{r dt-join-updatejoin}
a[b, on=.(id), y := i.y ]    # create column, assign to each matched row of a 
a[!b, on=.(id), y := 999L ]  # assign to unmatched rows of a
```

The `i.*` syntax allows for unambiguously referring to columns from `i` (in case the two tables have columns with the same names). Similarly, the `x.*` prefix can be used to refer to columns of `x`.

```{block2 dt-updatejoin-beware, type='rmd-caution'}
**Beware multiple matches in an update join.** When there are multiple matches (\@ref(join-multimatch)), an update join will apparently only use the last one. [Unfortunately](https://github.com/Rdatatable/data.table/issues/2022), this is done silently. Try `b[a, on=.(id), x := i.x, verbose = TRUE ][]`. At least with `verbose` on it helpfully reports that it assigned "to 3 row subset of 2 rows."
```
















